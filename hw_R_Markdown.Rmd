---
title: "Experimental_economics_hw"
author: "shan zhang"
date: "4/25/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, ## Show all R output
  cache = TRUE, ## Cache the results to increase performance.
  message = FALSE ## Suppress messages (e.g. about namespace conflicts)
  ) 
```

### preliminaries
```{r packs, cache=FALSE}
## load pacman
if(!require("pacman")) install.packages("pacman")
## load packages using pacman::p_load
p_load(tidyverse, broom, huxtable, ggplot2, cowplot, estimatr)
theme_set(theme_minimal())
```


###Q1.Simulation

```{r sim}
## create a function for simulating data
sim_fun <- function(n) {
  ## initialize an empty data frame
  ite_df <- as_tibble(matrix(ncol = 4, nrow = n))
  ## assign names 
  names(ite_df) <-c("y_1", "y_0", "D", "treat")
  ## populate the variables with simulated data
  ## y_0 is the control outcome, y_1 is the treatment outcome, and assign
  ## treatment 
  ite_df %>%
    mutate(y_1 = rnorm(n, 21500, 5000)) %>%
    mutate(y_0 = rnorm(n, 20000, 5000)) %>%
    ## assign to treatment
    mutate(D = sample(c(0, 1), 
                size = n, 
                replace = TRUE, 
                prob = c(0.5, 0.5))) %>%
   ## treatment effect
    mutate(treat = y_1 - y_0)
}

set.seed(20497)
simu_df <-  sim_fun(10000)
```

### 1) ATE and True ATE

### 1) ATE and True ATE
```{r ate}
## average treatment outcome
avg_t <- simu_df %>%
  filter(D == 1) %>%
  summarise(mean(y_1))
## average control outcome
avg_c <- simu_df %>%
  filter(D == 0) %>%
  summarise(mean(y_0))
## average treatment effect (ATE)
ate <- avg_t - avg_c


## true average treatment effect
true_ate <- simu_df %>%
  summarise(mean(treat))

ate
true_ate
```

**The difference between the ATE and the true ATE is very minimal. The ATE is 1,499.75 whereas the true ATE is 1,500.93.**

### 2) Distributions of compliers, never-takers, and always takers
```{r samples}
## Always takers
Always_takers_count = simu_df %>% 
  filter(treat > 1000) %>%
  tally()

compliers_count = simu_df %>% 
  filter( treat <= 1000 & treat >= 0) %>%
  tally()

Never_takers_count = simu_df %>%
  filter(treat < 0) %>%
  tally()


```

**In my simulation sample, there are 5344 always takers, 536 compliers and 4120 never takers. So the distribution is 53.44%, 5.36% and 41.2%.**


### 3) What is the average impact of the training for compliers, always takers, and never takers?

```{r}
Always_takers = simu_df %>% 
  filter(treat > 1000)

true_ate_a <- Always_takers %>%
  summarise(mean(treat))

Compliers = simu_df %>% 
  filter(treat <= 1000 & treat >= 0)

true_ate_c <- Compliers %>%
  summarise(mean(treat))


Never_takers = simu_df %>% 
  filter(treat < 0)

true_ate_n <- Never_takers %>%
  summarise(mean(treat))

```

**The average impact of the training for always takers is 6912.229, for compliers is 496.851 and for never taker -5229.72.**


### 4) Why is it reasonable to assume there are no defiers given our assumptions about how people are making participation decisions?

**For the always takers who are in control group, they are the defliers. And for the never takers who is in treatment group, they are defliers. **


###5) Use a regression to estimate the intent-to-treat effect in your sample. What is the point estimate and the 95% confidence interval around the estimate?

```{r}
## Define participate P and Y

simu_1 = simu_df %>%
    mutate( P = ifelse(treat >1000 |  treat >= 0 & treat <= 1000 & D == 1, 
                        1 , 
                        0)) %>%
  mutate(Y = P*y_1 + (1-P)*y_0)

## ITE

reg1 = lm(Y ~ D, data = simu_1)
tidy(reg1, conf.int = TRUE)



```

### 7)Use two-stage least squares to estimate the local average treatment effect in your sample. Comment on the point estimate and the 95% confidence interval around the estimate. How does this compare to the effects we estimated earlier in this problem?

```{r}
library(AER)
reg2 = ivreg(Y ~ P|D, data = simu_1)
tidy(reg2, conf.int = TRUE)


```

### 8) Re-run your code but drawing a sample of 1, 000, 000 observations instead of 10, 000. How does the estimated LATE compare to the earlier treatment effects now?

```{r}
simu_df_2 <-  sim_fun(1000000)
simu_2 = simu_df_2 %>%
    mutate( P = ifelse(treat >1000 |  treat >= 0 & treat <= 1000 & D == 1, 
                        1 , 
                        0)) %>%
  mutate(Y = P*y_1 + (1-P)*y_0)
reg3 = ivreg(Y ~ P|D, data = simu_2)
tidy(reg3, conf.int = TRUE)

```


## Q2 Suppose a researcher is evaluating an experiment using a sample that consists of 50% compliers, 25% always takers, and 25% never takers. The researcher decides to estimate the intent-to-treat effect but dropping people who did not comply with the treatment protocol from the sample. After dropping people who did not comply with their treatment assignment from the sample, what is the distribution of compliers, always takers, and never takers in the treatment group? In the control group? Why is this a problem?


** There are non-compliers in both always taker and never takers groups. More specifically, in the treatment group, the never takers can be the non-compliance. After dropping those non-compliers, the distribution of compliers, always takers and never takers will change from 50%, 25% and 25% to 67%, 33%, and 0. In the control group, always takers can be non-compliers. Then the distribution of compliers, always takers and never takers will change from 50%, 25% and 25% to 67%, 0, and 33%. The problem is that after droping the non-compliers, the control group and treatment group are not comparable anymore since the treatment is not independent on the complier, always takers and never takers anymore. This will cause bias on our estimation of treatment effect.**


## Q3 Stratified Effects

#What would the pooled treatment effect be if estimated using an OLS regression of the outcome on treatment and block fixed effects? How much weight does each block get in the pooled estimate?

We know:
$$\Delta^{OLS} = \sum_{b} \frac{N_{b}*Var(T_{i},b)}{N*Var(T_{i})}\Delta_{b}$$

And $$Var(T_{i},b) = N_{b}*P*(1-P)$$

For the $$Var(T_{i})=N*P*(1-P)$$

here p = (50 + 25 + 100 + 150 + 30)/900 = 39%
So $Var(T_{i})$ = 900 * 0.39 * 0.61 = 214.11
Thus $$\Delta^{OLS} = \frac{100*25*(-1)+100*18.75*(0)+200*50*(1) + 200*(37.5)*(2) + 300*27*(3)}{900*214.11} = 0.2429$$

##Q4 Power Calculations

## 1). What is your minimum detectable effect if the intracluster correlation is 0?

Effective sample size = $\frac{N}{1+(n-1)*\rho}$

When $\rho$ = 0, ESS = 10000

$$N = \frac{\sigma^{2}}{\delta^{2}}\frac{(t_{\alpha^{2}/2}+t_{\beta})^{2}}{Var(T_{i})}$$
$N^{*} = 10000$,$\frac{(t_{\alpha^{2}/2}+t_{\beta})^{2}}= 2.8^{2}$, $Var(T_{i}) = 0.25$, then calculate $\delta$,

We get $\delta_{1}$ = 2.5

## 2). What is your minimum detectable effect if the intracluster correlation is 0.2?

Effective sample size = $\frac{N}{1+(n-1)*\rho}$

When $\rho$ = 0.2, ESS = 409

$$N = \frac{\sigma^{2}}{\delta^{2}}\frac{(t_{\alpha^{2}/2}+t_{\beta})^{2}}{Var(T_{i})}$$

$N^{*}$ = 409 ,$\frac{(t_{\alpha^{2}/2}+t_{\beta})^{2}}= 2.8^{2}$, $Var(T_{i}) = 0.25$, then calculate $\delta$,

We get $\delta_{2}$ = 12.3


## 3). How do these answers change if you can control for baseline characteristics that explain 20 percent of residual variation?

When $R^{2} = 0.2$, $\sigma^{*2} = \sigma^{2}*(1-0.2)$

Thus $\delta_{1}^{*} = 2.236$ and $\delta_{2}^{*} = 11$












